{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfdccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa38ee",
   "metadata": {},
   "source": [
    "Device dignostics code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d284dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cb9c6",
   "metadata": {},
   "source": [
    "Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c7ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"E:\\Pytorch Datasets\\Classification\\wine+quality\\winequality-white.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200b77bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718ad200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = list(df.iloc[:, -1])\n",
    "from collections import Counter\n",
    "len(Counter(li))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3cae3",
   "metadata": {},
   "source": [
    "Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01dafd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.iloc[:, :-1])\n",
    "y = np.array(df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369c4851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726d8e8",
   "metadata": {},
   "source": [
    "Converting numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7efb6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e032e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85637ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 11]), torch.Size([4898]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc92b72",
   "metadata": {},
   "source": [
    "Spliting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6700faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5261c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3918, 11]),\n",
       " torch.Size([980, 11]),\n",
       " torch.Size([3918]),\n",
       " torch.Size([980]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a648eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train.to(device), X_test.to(device), y_train.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02449f6",
   "metadata": {},
   "source": [
    "Build a Linear model by inheriting nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18b92be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=11, out_features=32)\n",
    "        self.layer2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.layer3 = nn.Linear(in_features=64, out_features=64)\n",
    "        self.layer4 = nn.Linear(in_features=64, out_features=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "    \n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca28fd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[ 0.0608,  0.2182,  0.1040, -0.1690, -0.2866, -0.0166, -0.1911,  0.1346,\n",
       "                        0.0939, -0.2838,  0.0043],\n",
       "                      [-0.1032, -0.0808, -0.1374, -0.0154,  0.2914, -0.2671, -0.1776,  0.0959,\n",
       "                        0.0740,  0.1071, -0.0094],\n",
       "                      [ 0.0938, -0.0883,  0.1158,  0.1331,  0.1799,  0.2305, -0.1700,  0.1836,\n",
       "                       -0.0399, -0.0441,  0.2818],\n",
       "                      [-0.0570,  0.0131,  0.1590, -0.2251, -0.0226, -0.0937,  0.2001,  0.2398,\n",
       "                        0.1867,  0.1259, -0.2143],\n",
       "                      [ 0.0109,  0.2701, -0.1382, -0.0286,  0.1026, -0.0905, -0.0731,  0.2955,\n",
       "                       -0.1831,  0.1475,  0.2403],\n",
       "                      [-0.2572, -0.2141,  0.2719,  0.1408, -0.0313, -0.2405,  0.0668,  0.2313,\n",
       "                        0.0404,  0.1504, -0.0407],\n",
       "                      [ 0.1079,  0.2350,  0.0645,  0.1669, -0.0527,  0.0309,  0.1093, -0.2260,\n",
       "                       -0.2790,  0.2386,  0.1349],\n",
       "                      [-0.2479, -0.2018, -0.1969,  0.0650, -0.0797, -0.0243, -0.1095,  0.2877,\n",
       "                       -0.1906,  0.1977, -0.0072],\n",
       "                      [ 0.1792,  0.1518,  0.0817,  0.0669, -0.2938,  0.2344,  0.0386,  0.1605,\n",
       "                        0.1851,  0.0935,  0.2521],\n",
       "                      [ 0.2289,  0.0933, -0.2283,  0.0832,  0.1811,  0.2202, -0.1464,  0.1797,\n",
       "                        0.0353,  0.0867,  0.0572],\n",
       "                      [ 0.1693, -0.0031,  0.0527, -0.2725,  0.1004,  0.0376, -0.0950,  0.2555,\n",
       "                       -0.2849,  0.0686,  0.2544],\n",
       "                      [ 0.1914,  0.1403,  0.2272,  0.0346, -0.1917, -0.1366, -0.0499,  0.1032,\n",
       "                       -0.0139,  0.2076,  0.2619],\n",
       "                      [-0.1273, -0.1803, -0.1625, -0.0324,  0.1354, -0.2734,  0.1867,  0.0843,\n",
       "                        0.2766,  0.2141,  0.1633],\n",
       "                      [-0.1882,  0.2158,  0.1463,  0.0314, -0.2260,  0.2271,  0.0974, -0.3006,\n",
       "                       -0.0428, -0.1148,  0.2821],\n",
       "                      [-0.1144, -0.1515,  0.2116, -0.2357,  0.2270,  0.1266, -0.0565, -0.0325,\n",
       "                        0.2344, -0.2747,  0.0966],\n",
       "                      [-0.1019, -0.0930, -0.2989,  0.1169,  0.2366,  0.0848,  0.1331, -0.2994,\n",
       "                       -0.1465, -0.1252,  0.0420],\n",
       "                      [-0.2820,  0.0335,  0.2369, -0.2146,  0.0427,  0.1415, -0.2219,  0.0979,\n",
       "                        0.1238,  0.0544, -0.0922],\n",
       "                      [-0.2715,  0.1415,  0.0348, -0.1844, -0.2434,  0.0074, -0.2565,  0.1465,\n",
       "                        0.0316,  0.0591,  0.0087],\n",
       "                      [ 0.2175, -0.0574, -0.0449,  0.0895,  0.1803, -0.1609,  0.1019, -0.0165,\n",
       "                        0.0820, -0.0740, -0.1498],\n",
       "                      [ 0.0893,  0.2810, -0.1266, -0.0492,  0.2349, -0.2825, -0.0630,  0.1804,\n",
       "                        0.2932,  0.2906, -0.2395],\n",
       "                      [ 0.2579,  0.2589, -0.1180, -0.2950, -0.1304, -0.1947,  0.0864,  0.0406,\n",
       "                       -0.0784,  0.2173, -0.0623],\n",
       "                      [-0.1537,  0.0824,  0.2407,  0.2177, -0.2274,  0.2004, -0.0681, -0.0760,\n",
       "                       -0.0509,  0.1625,  0.2707],\n",
       "                      [-0.0906, -0.2044, -0.0329, -0.0690, -0.1192,  0.2381, -0.0928,  0.0206,\n",
       "                       -0.0637, -0.0077,  0.0512],\n",
       "                      [ 0.0612, -0.2374,  0.0375,  0.2837, -0.1525, -0.1345, -0.0955,  0.1403,\n",
       "                        0.0532, -0.0779, -0.2497],\n",
       "                      [ 0.1471,  0.0077, -0.1222,  0.2324, -0.2040,  0.1138, -0.1938,  0.2273,\n",
       "                        0.0625, -0.1327,  0.1076],\n",
       "                      [ 0.1655,  0.2793,  0.0215, -0.2078,  0.2135, -0.2752, -0.0736, -0.1318,\n",
       "                        0.0360,  0.1092,  0.0563],\n",
       "                      [-0.2485, -0.0615,  0.0352,  0.0075,  0.0236,  0.1328,  0.0313,  0.2661,\n",
       "                        0.1947, -0.1213,  0.0012],\n",
       "                      [ 0.0722, -0.3001,  0.1625, -0.1178,  0.2548,  0.2471,  0.1081, -0.2813,\n",
       "                       -0.2397,  0.2583,  0.2313],\n",
       "                      [-0.1342,  0.2976, -0.2914,  0.1104, -0.1162, -0.2381,  0.0721, -0.1914,\n",
       "                        0.0047,  0.0950,  0.0100],\n",
       "                      [-0.0235, -0.1918, -0.2434, -0.2222,  0.0149, -0.1590,  0.2569, -0.0224,\n",
       "                       -0.1254, -0.0517,  0.0304],\n",
       "                      [-0.0249,  0.1681,  0.1945,  0.0362,  0.1122,  0.1232, -0.0372,  0.1386,\n",
       "                       -0.2523, -0.2587,  0.0675],\n",
       "                      [-0.2659, -0.2034, -0.2138, -0.1010,  0.1763,  0.1339,  0.2001, -0.1588,\n",
       "                       -0.2668,  0.1300,  0.2528]])),\n",
       "             ('layer1.bias',\n",
       "              tensor([-0.2680, -0.1161, -0.2349, -0.2717,  0.1585,  0.2858,  0.1992, -0.1173,\n",
       "                       0.1672, -0.0296,  0.0163,  0.1728, -0.2371, -0.1031,  0.0699, -0.2017,\n",
       "                      -0.0339,  0.0102,  0.1532,  0.0614,  0.1984, -0.1731, -0.2828,  0.1627,\n",
       "                       0.1498, -0.0999,  0.1285,  0.0348, -0.0535, -0.2454,  0.1443,  0.0287])),\n",
       "             ('layer2.weight',\n",
       "              tensor([[-0.0352,  0.1567, -0.0323,  ...,  0.1404, -0.0977, -0.1519],\n",
       "                      [-0.0472, -0.0406,  0.0212,  ..., -0.0980,  0.1491,  0.1671],\n",
       "                      [ 0.1384,  0.1583,  0.1633,  ...,  0.1602, -0.0810,  0.0952],\n",
       "                      ...,\n",
       "                      [-0.0416,  0.0135,  0.0500,  ...,  0.0078, -0.1352,  0.0387],\n",
       "                      [-0.1732, -0.0102, -0.1153,  ...,  0.1737,  0.0894, -0.1749],\n",
       "                      [-0.0564,  0.0827,  0.0308,  ..., -0.0405, -0.1765,  0.0238]])),\n",
       "             ('layer2.bias',\n",
       "              tensor([-0.0800,  0.0087, -0.0982,  0.1648,  0.0161,  0.1668,  0.1414,  0.1205,\n",
       "                       0.0707, -0.0435, -0.1588,  0.0111,  0.1158, -0.0237,  0.0360,  0.1467,\n",
       "                      -0.1564,  0.0148,  0.0977, -0.1276, -0.0470, -0.0718,  0.1199, -0.1686,\n",
       "                       0.1052, -0.1618, -0.1307,  0.0926,  0.0882,  0.0750, -0.0435,  0.1715,\n",
       "                       0.1135,  0.0159,  0.0094, -0.1670, -0.1029,  0.0432,  0.0576,  0.1666,\n",
       "                      -0.0870,  0.1017, -0.1219, -0.1534,  0.1145,  0.0547, -0.0297, -0.1359,\n",
       "                       0.0388, -0.0197, -0.0517, -0.1290, -0.1097, -0.1306,  0.0142, -0.1684,\n",
       "                      -0.1184,  0.0578, -0.0892, -0.0701,  0.1116,  0.1711,  0.0274,  0.0334])),\n",
       "             ('layer3.weight',\n",
       "              tensor([[-0.0346,  0.1247, -0.0882,  ...,  0.0593, -0.0792, -0.0453],\n",
       "                      [-0.0967, -0.0858,  0.0749,  ..., -0.0982,  0.0311,  0.0781],\n",
       "                      [ 0.0012, -0.0238, -0.0386,  ...,  0.0715, -0.0957,  0.1034],\n",
       "                      ...,\n",
       "                      [-0.1195, -0.0131, -0.0790,  ..., -0.0998, -0.0065,  0.0642],\n",
       "                      [-0.0565,  0.1066, -0.0488,  ..., -0.0348, -0.1060,  0.1244],\n",
       "                      [-0.0259,  0.0180, -0.0874,  ..., -0.0870,  0.0706, -0.0094]])),\n",
       "             ('layer3.bias',\n",
       "              tensor([-0.0863, -0.0814, -0.0831,  0.0505,  0.1241, -0.0726, -0.0156,  0.0133,\n",
       "                      -0.0958,  0.0607, -0.0352,  0.0581, -0.0465, -0.1049,  0.0178,  0.0417,\n",
       "                       0.0114,  0.0044, -0.0958,  0.0496, -0.1040, -0.1215, -0.0802, -0.1146,\n",
       "                       0.0907, -0.0398,  0.0094,  0.0161, -0.0556, -0.0444,  0.0482, -0.1157,\n",
       "                       0.0193, -0.0178,  0.0988,  0.1232,  0.0173,  0.0550, -0.0632, -0.0093,\n",
       "                      -0.0211, -0.0752,  0.0028, -0.0175, -0.0841, -0.0821, -0.0440,  0.0164,\n",
       "                       0.0967, -0.0211,  0.0955,  0.1214, -0.1137,  0.1053, -0.0861,  0.1122,\n",
       "                      -0.0353,  0.0428, -0.0423,  0.0505, -0.0164,  0.1113, -0.1036,  0.0090])),\n",
       "             ('layer4.weight',\n",
       "              tensor([[ 5.6535e-02,  7.6503e-02,  1.0458e-01, -8.1562e-02, -6.8892e-02,\n",
       "                        1.0378e-01, -6.6277e-02, -7.4791e-02,  9.4368e-02, -5.7668e-03,\n",
       "                        3.2369e-02, -7.0632e-02, -1.1185e-01,  1.4048e-02,  6.7698e-03,\n",
       "                       -7.6257e-02,  7.4101e-02,  7.8806e-02, -8.4469e-03, -1.0492e-01,\n",
       "                        1.1174e-01,  8.4399e-02,  3.3688e-02,  1.1424e-02,  9.4805e-02,\n",
       "                        7.5994e-02,  3.6220e-02, -2.5413e-02, -4.0516e-02,  9.2648e-02,\n",
       "                        8.0489e-02, -5.3897e-02,  5.9072e-02,  3.9662e-02,  8.8078e-02,\n",
       "                        1.0090e-01, -6.4472e-02,  4.2505e-02,  6.4211e-02, -5.5330e-02,\n",
       "                        3.1413e-02, -8.4906e-02, -3.7369e-02,  3.7784e-02,  7.2876e-03,\n",
       "                        2.2440e-03,  7.0170e-03, -4.9026e-02, -3.2328e-02,  2.4637e-02,\n",
       "                        1.0736e-01,  4.4429e-02,  2.4637e-02, -1.4080e-02,  8.2280e-02,\n",
       "                        1.1301e-01,  7.7058e-02,  1.3546e-02, -2.4551e-02, -9.3180e-02,\n",
       "                       -7.3958e-02, -3.2486e-02,  3.2604e-02,  7.7165e-02],\n",
       "                      [-1.2219e-01, -2.2713e-02, -8.9773e-02,  1.0738e-01,  1.5973e-02,\n",
       "                       -1.0881e-01,  7.4325e-02,  6.8354e-02, -4.7850e-02, -7.1399e-02,\n",
       "                        7.6472e-02, -5.7437e-03, -4.7437e-02, -9.7605e-02, -7.1707e-02,\n",
       "                       -6.7270e-02, -6.3958e-02, -1.1732e-02,  1.3454e-02, -8.8560e-02,\n",
       "                        1.2405e-01,  9.6489e-02, -1.1286e-01,  6.5570e-02,  4.6297e-02,\n",
       "                        1.0006e-01,  1.2126e-01,  6.0552e-02, -7.0416e-02, -1.4336e-02,\n",
       "                       -9.9068e-02, -1.2269e-01,  5.6544e-02,  2.9900e-02, -1.2266e-01,\n",
       "                       -3.1034e-02, -1.1382e-01,  5.0086e-02,  1.4173e-02,  4.5676e-02,\n",
       "                       -3.5679e-02,  8.7095e-02, -3.1262e-02,  6.1740e-02,  4.9906e-02,\n",
       "                       -1.1247e-01,  2.5514e-02,  1.2260e-01, -4.3491e-02,  1.1103e-01,\n",
       "                       -4.0131e-02,  1.0993e-01,  7.6764e-03,  8.1246e-02, -5.2869e-02,\n",
       "                        1.0252e-01, -4.9286e-02, -1.2429e-01, -1.0731e-01, -6.7753e-02,\n",
       "                       -1.0682e-01, -6.2830e-02,  9.1705e-02,  5.3988e-02],\n",
       "                      [-8.6820e-02,  5.3598e-02, -7.0160e-02, -1.3953e-02, -1.0343e-01,\n",
       "                        1.0754e-02, -1.9885e-02,  9.0957e-02,  5.2795e-02, -5.5356e-02,\n",
       "                        2.2047e-02,  1.1133e-01,  1.2341e-01, -7.1500e-02, -3.2877e-02,\n",
       "                       -1.1532e-01, -5.6550e-03,  8.3401e-02,  1.1854e-01, -2.5086e-02,\n",
       "                        1.1455e-01,  5.4518e-02,  1.1229e-01,  9.8880e-03,  7.9958e-02,\n",
       "                        1.4360e-02,  6.3423e-02,  6.6692e-02, -2.2461e-02,  1.0759e-01,\n",
       "                       -5.7367e-02,  1.1132e-01,  3.7824e-02,  1.2409e-01, -1.2366e-01,\n",
       "                        3.3652e-02,  5.7765e-02,  3.6104e-02, -1.1874e-01, -4.0507e-02,\n",
       "                        4.7958e-04, -3.6524e-02, -1.1240e-01,  2.3915e-02,  5.4422e-02,\n",
       "                       -3.5852e-02,  8.3249e-02,  8.6908e-02,  1.5013e-02,  8.8867e-02,\n",
       "                       -1.2202e-01,  1.0966e-01,  1.0689e-01, -2.4335e-02, -9.6197e-02,\n",
       "                       -9.2143e-02, -1.0824e-01,  1.9634e-02, -1.1993e-01,  9.8644e-02,\n",
       "                       -3.0926e-02, -1.1158e-01, -9.7921e-02, -5.6138e-02],\n",
       "                      [-3.2124e-02, -3.4841e-02, -1.9851e-02,  6.5672e-02,  1.0291e-01,\n",
       "                        5.4305e-02,  2.2116e-02,  7.5614e-02,  1.0164e-02,  5.8072e-02,\n",
       "                       -5.0295e-02, -2.6297e-03,  4.0271e-02, -1.8423e-02, -5.2063e-02,\n",
       "                        1.6796e-02, -1.0939e-01,  8.5893e-02, -1.1318e-02, -3.0844e-02,\n",
       "                        1.5296e-02,  1.1105e-01, -5.2314e-02, -7.3925e-02,  1.1607e-01,\n",
       "                        1.2275e-01,  5.4983e-03,  7.1764e-02, -1.1404e-01,  5.9195e-02,\n",
       "                       -4.5953e-02, -2.4753e-02, -8.8007e-02, -2.0405e-02, -5.1001e-02,\n",
       "                       -6.0347e-02,  5.6215e-02, -6.9111e-02, -8.8093e-03,  4.4943e-03,\n",
       "                        2.4148e-02, -8.7733e-02,  5.6622e-02, -4.3688e-02, -1.1991e-01,\n",
       "                        7.6328e-03,  3.9817e-02,  4.0138e-02, -5.5378e-02, -5.4789e-02,\n",
       "                       -1.1543e-01,  6.4834e-02,  1.0128e-02, -5.1219e-02,  8.8119e-02,\n",
       "                        9.5088e-02, -1.1306e-01,  2.5106e-02, -3.5436e-02, -1.1179e-01,\n",
       "                        6.9128e-02,  2.7538e-02,  6.2512e-02, -6.4788e-02],\n",
       "                      [-3.2772e-02, -7.9160e-02, -1.0596e-01, -2.7348e-02,  4.6245e-02,\n",
       "                       -5.4365e-02, -3.7214e-02, -2.7585e-02,  3.2153e-02, -6.2942e-02,\n",
       "                       -4.4632e-02, -7.2160e-02,  4.8595e-02,  6.8759e-02,  8.4597e-02,\n",
       "                       -2.6966e-02,  4.7948e-02,  7.7513e-02,  2.0248e-02, -3.3087e-02,\n",
       "                        1.1305e-01,  5.2895e-02, -4.2796e-02,  1.2329e-01, -1.0614e-01,\n",
       "                       -1.1955e-01,  9.2689e-02, -2.1568e-02,  2.5533e-02, -3.5612e-02,\n",
       "                       -5.0440e-02, -1.2039e-01,  2.0375e-02, -7.8412e-02, -8.1579e-03,\n",
       "                        1.1568e-02, -9.0388e-02, -1.1766e-01,  5.0492e-03,  9.3674e-02,\n",
       "                        4.3352e-02, -2.6810e-02, -2.3763e-02,  4.1563e-02,  1.4530e-02,\n",
       "                       -4.0301e-02,  1.0649e-01, -3.3291e-02,  9.5442e-02,  5.1864e-02,\n",
       "                        7.8100e-02,  3.9752e-02,  3.6486e-03, -9.0710e-02, -3.4494e-02,\n",
       "                        9.4240e-02, -3.9232e-02, -5.3144e-02, -4.0551e-02, -1.1786e-02,\n",
       "                       -6.0059e-02,  3.3484e-02, -9.7231e-02, -5.7688e-03],\n",
       "                      [ 2.2624e-02, -6.2917e-02, -7.9010e-02,  7.9649e-02,  8.5234e-02,\n",
       "                       -3.4940e-04,  4.3513e-02,  3.8919e-02, -5.7731e-02,  7.3460e-02,\n",
       "                       -2.9395e-02,  2.0276e-02, -1.1977e-01,  8.0979e-02, -2.7672e-02,\n",
       "                       -6.4339e-02, -9.9460e-02, -1.1523e-01, -8.2446e-02,  1.1065e-01,\n",
       "                       -1.1927e-01, -7.0031e-02,  3.7053e-02, -1.0072e-01, -1.2334e-01,\n",
       "                        6.7510e-02, -5.5993e-02, -1.1850e-01, -1.1273e-01,  6.4971e-02,\n",
       "                       -2.0838e-02,  6.0954e-02, -7.3536e-02,  6.4480e-02,  3.7841e-02,\n",
       "                       -2.4761e-02, -8.8074e-02,  1.2060e-01,  6.9100e-02, -1.0442e-01,\n",
       "                       -2.9436e-03, -2.3504e-03,  2.6232e-02, -1.2098e-01, -6.5860e-02,\n",
       "                        6.7117e-02,  8.6765e-02,  7.7903e-02, -1.5236e-02, -1.0137e-01,\n",
       "                        1.2210e-01, -8.8800e-02,  9.5787e-03, -2.0712e-02,  1.1485e-01,\n",
       "                        8.9356e-02, -6.0764e-03,  4.2794e-02, -5.0304e-02,  5.8500e-02,\n",
       "                       -3.6302e-02,  6.9072e-02,  8.8488e-02,  9.8774e-02],\n",
       "                      [-1.1644e-01, -1.0452e-01,  7.6202e-02,  6.2289e-02, -3.0191e-02,\n",
       "                        4.0400e-02,  6.3428e-02,  2.7074e-02, -5.2194e-02, -5.3177e-02,\n",
       "                        9.3207e-02, -1.0343e-02, -1.8536e-03,  9.1744e-02, -6.4325e-02,\n",
       "                       -5.2669e-02,  3.7549e-02, -8.5966e-02, -7.9692e-02, -9.2992e-02,\n",
       "                        9.8508e-02,  9.7240e-02, -4.8426e-02, -1.0064e-01,  5.9193e-02,\n",
       "                        2.0163e-02,  8.8733e-02, -8.7837e-02, -1.0573e-01,  7.4442e-02,\n",
       "                       -8.8718e-02,  1.2113e-01, -3.5200e-02, -6.7242e-02, -3.5057e-02,\n",
       "                       -4.6238e-02, -4.9738e-03,  1.1500e-01, -9.6611e-02,  6.9184e-02,\n",
       "                        1.0141e-01,  1.2431e-02,  9.1808e-02, -2.2134e-02, -7.9447e-02,\n",
       "                        9.4920e-02,  2.3507e-02, -2.2314e-02, -1.1229e-01, -7.0885e-02,\n",
       "                        7.6334e-02,  3.6656e-02,  7.9084e-02,  5.5402e-02, -1.1669e-01,\n",
       "                        6.6937e-02, -8.1572e-02,  6.9292e-02, -8.7084e-02, -1.3384e-02,\n",
       "                       -7.9868e-02, -7.1228e-02,  6.6654e-03,  2.7768e-02],\n",
       "                      [-2.6124e-02, -1.1130e-02, -1.7524e-02, -3.5194e-02,  6.4002e-02,\n",
       "                       -9.4859e-02,  1.1601e-01,  7.6579e-03, -3.0963e-02, -3.6127e-03,\n",
       "                       -1.6295e-02, -7.6563e-02,  4.3021e-02,  1.1133e-01, -9.9488e-02,\n",
       "                        9.5260e-02,  6.1792e-02, -6.6056e-02,  1.1680e-01, -3.0451e-02,\n",
       "                       -1.2499e-01, -8.1662e-02, -8.2157e-02,  5.7697e-02,  1.0303e-01,\n",
       "                        1.2018e-01, -3.2353e-02,  4.6499e-02,  6.3595e-02,  8.7967e-02,\n",
       "                       -5.0355e-03, -5.2640e-02,  7.5415e-02,  4.3254e-02,  8.9190e-02,\n",
       "                       -1.1696e-01, -1.0098e-01, -1.2305e-01,  1.0122e-01, -1.0394e-01,\n",
       "                        7.0808e-02, -7.0610e-02,  1.2429e-01,  2.2375e-02,  9.6226e-02,\n",
       "                       -8.3477e-02, -6.3850e-02, -1.1891e-01, -4.0772e-02, -5.7939e-02,\n",
       "                       -1.0355e-01,  8.0005e-02, -6.1114e-02,  6.5017e-02,  5.9852e-02,\n",
       "                        1.1345e-01, -8.2351e-02,  2.0344e-02,  1.0015e-01, -2.6713e-02,\n",
       "                       -1.2339e-01, -9.3386e-05, -8.9162e-02,  7.1542e-02]])),\n",
       "             ('layer4.bias',\n",
       "              tensor([ 0.0591,  0.0511,  0.0759,  0.0415, -0.0366, -0.0463, -0.0852,  0.0340]))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdede71",
   "metadata": {},
   "source": [
    "Testing everything is fine using dummy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd344a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_logits = model(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b4ecc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([980, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dcceef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.Sigmoid()\n",
    "y_pred = torch.round(activation(y_logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ac93b",
   "metadata": {},
   "source": [
    "Choosing Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f8aeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef7e9b",
   "metadata": {},
   "source": [
    "Writing Training and Test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc34c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7922a318",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 8 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m y_logits \u001b[38;5;241m=\u001b[39m model(X_train)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(y_logits)\n\u001b[1;32m---> 10\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_train, y_pred)\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\tharu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tharu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\tharu\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tharu\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 8 is out of bounds."
     ]
    }
   ],
   "source": [
    "epochs = 101\n",
    "\n",
    "for i in range(1, epochs):\n",
    "    #training\n",
    "    model.train()\n",
    "\n",
    "    y_logits = model(X_train).squeeze()\n",
    "    y_pred = torch.sigmoid(y_logits)\n",
    "\n",
    "    train_loss = loss_fn(y_logits, y_train)\n",
    "    train_acc = accuracy_score(y_train, y_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    #testing \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model(X_test).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "        test_loss = loss_fn( test_logits, y_test)\n",
    "        test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Epoch: {i} | Train Loss: {train_loss:.5f} | Train Accuracy: {train_acc:.2f} | Test Loss: {test_loss:.5f} | Test Accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30858bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
